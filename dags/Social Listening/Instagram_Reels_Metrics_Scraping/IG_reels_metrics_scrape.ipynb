import re, json, requests
import pandas as pd
from bs4 import BeautifulSoup
import time
import gdown

cookies = {
  'mid': 'ZRXMegALAAFCcQdoVe_4BEZ1pv1F',
  'ig_did': '5B004BCC-7C1A-4952-B7E4-41F4E748DBB6',
  'ig_nrcb': '1',
  'datr': 'eMwVZS08kqG5wUT8mv6b9omF',
  'csrftoken': 'B3GPSZXrlXZuxE2kJhRZG1G3cFWOcnDI',
}

headers = {
    'Accept': '*/*',
    'Accept-Language': 'en-US,en;q=0.9',
    'Cache-Control': 'no-cache',
    'Connection': 'keep-alive',
    'Content-Type': 'application/x-www-form-urlencoded',
    'Origin': 'https://www.instagram.com',
    'Pragma': 'no-cache',
    'Sec-Fetch-Dest': 'empty',
    'Sec-Fetch-Mode': 'cors',
    'Sec-Fetch-Site': 'same-origin',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36 Edg/117.0.2045.60',
    'X-ASBD-ID': '129477',
    'X-CSRFToken': 'B3GPSZXrlXZuxE2kJhRZG1G3cFWOcnDI',
    'X-FB-Friendly-Name': 'PolarisPostActionLoadPostQueryQuery',
    'X-FB-LSD': 'AVpkehtFeZo',
    'X-IG-App-ID': '936619743392459',
    'dpr': '1.5',
}

data = {
    'av': '0',
    '__d': 'www',
    '__user': '0',
    '__a': '1',
    '__req': '4',
    '__hs': '19639.HYP:instagram_web_pkg.2.1..0.0',
    'dpr': '1.5',
    '__ccg': 'UNKNOWN',
    '__rev': '1009121219',
    '__s': 'xixpm0:zjjndl:rb5t75',
    '__hsi': '7288018530036480263',
    '__dyn': '7xeUmwlEnwn8K2WnFw9-2i5U4e1ZyUW3qi2K360CEbo1nEhw2nVE4W0om78b87C0yE5ufz81s8hwGwQwoEcE7O2l0Fwqo31w9a9x-0z8-U2zxe2GewGwso88cobEaU2eUlwhEe87q7-0iK2S3qazo7u1xwIw8O321LwTwKG1pg661pwr86C1mwraCgoK',
    '__csr': 'hI7IjOp5H8QQbHivJp97hXyLZeh7GjmA-uFLkygSeWQmm4K9Uxa5A-aG8GaLGleJqWDhE-RAihybACBDy4iqAEzziuEB2E9oizVpo014Q8Aw1rQ3e0k208xa02iIi5EfQ19xm1iBx-3FwJjg0Ey0k5yE1v8EK040E-4oJw9e0tkw05P209sw',
    '__comet_req': '7',
    'lsd': 'AVpkehtFeZo',
    'jazoest': '21063',
    '__spin_r': '1009121219',
    '__spin_b': 'trunk',
    '__spin_t': '1696874044',
    'fb_api_caller_class': 'RelayModern',
    'fb_api_req_friendly_name': 'PolarisPostActionLoadPostQueryQuery',
    'server_timestamps': 'true',
    'doc_id': '10015901848480474',
}

def get_views(reel_link):
    reel_regex = "https://www.instagram.com/reel/(.*)/.*"
    m = re.match(reel_regex, reel_link)
    if m:
        reel_code = m.group(1)
    else:
        return 'Invalid Reel link'

    headers['Referer'] = 'https://www.instagram.com/reel/'+ reel_code + '/'
    data['variables'] = '{"shortcode":"' + reel_code + '","fetch_comment_count":40,"fetch_related_profile_media_count":3,"parent_comment_count":24,"child_comment_count":3,"fetch_like_count":10,"fetch_tagged_user_count":null,"fetch_preview_comment_count":2,"has_threaded_comments":true,"hoisted_comment_id":null,"hoisted_reply_id":null}'
    
    response1 = requests.post('https://www.instagram.com/api/graphql', cookies=cookies, headers=headers, data=data)
    
    print('Url--->', reel_link)
    
    try:
        response = response1.json()  # Parse the JSON response

        if response1.status_code != 200 or response.get("data", {}).get("xdt_shortcode_media") is None:
            return {
                "Play_count": "Not valid link",
                "Video_view_count": "Not valid link",
                "Like_count": "Not valid link",
                "Comment_count": "Not valid link"
            }

        media_data = response["data"]["xdt_shortcode_media"]
        
        return {
            "Play_count": media_data["video_play_count"],
            "Video_view_count": media_data["video_view_count"],
            "Like_count": media_data["edge_media_preview_like"]['count'],
            "Comment_count": media_data["edge_media_preview_comment"]['count']
        }

    except Exception as e:
        print(f"Error: {e}")
        return {
            "Play_count": "Error",
            "Video_view_count": "Error",
            "Like_count": "Error",
            "Comment_count": "Error"
        }

# You can change this file to use the one you have locally
id = "1dXg77KPq_5vSB42b6goNyr_akd1MTaaH6VH6kPSH3x8"
output = "Social_Media_Scraping.xlsx"
gdown.download(id=id, output=output)

input_file = 'Social_Media_Scraping.xlsx'
df = pd.read_excel(input_file, sheet_name='Instagram')

scraped_data = []
Like_count = []
Comment_count = []
Play_count = []
Video_view_count = []
url_list = []

for url in df['Reels_link']:
    scraped_result = get_views(url)
    print(scraped_result)
    Like_count.append(scraped_result['Like_count'])
    Comment_count.append(scraped_result['Comment_count'])
    Play_count.append(scraped_result['Play_count'])
    Video_view_count.append(scraped_result['Video_view_count'])
    scraped_data.append(scraped_result)
    url_list.append(url)
    time.sleep(3)

df = pd.DataFrame({
    'Post_link': url_list,
    'Like_count': Like_count,
    'Comment_count': Comment_count,
    'Play_count': Play_count,
    'Video_view_count': Video_view_count
})

df.to_excel('Instagram_reels_output.xlsx', sheet_name='likes_comments_views', index=False)

print(f'Data saved to Instagram_reels_output.xlsx, Sheet: likes_comments_views')
