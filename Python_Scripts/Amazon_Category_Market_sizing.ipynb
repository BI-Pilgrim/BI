{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89289a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from flask import Flask, render_template, request\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5e4d3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Extract_card(card,path):\n",
    "    try:\n",
    "        content = card.find_element('xpath',path)\n",
    "        return content\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Create a new column 'maxunitsold' based on conditions\n",
    "def calculate_maxunitsold(unitsold):\n",
    "    if unitsold == 0:\n",
    "        return 0\n",
    "    elif unitsold < 100:\n",
    "        return unitsold + 50\n",
    "    elif unitsold < 1000:\n",
    "        return unitsold + 100\n",
    "    elif unitsold < 10000:\n",
    "        return unitsold + 1000\n",
    "    else:\n",
    "        return unitsold * 2\n",
    "    \n",
    "\n",
    "\n",
    "def Scrape_Page(driver,inp_url):\n",
    "\n",
    "    driver.get(inp_url)\n",
    "    cards = driver.find_elements('xpath','//div[@data-cy=\"asin-faceout-container\"]')\n",
    "    Image_url = []\n",
    "    Product_Title = []\n",
    "    Quantity_sold = []\n",
    "    No_of_ratings = []\n",
    "    Selling_price = []\n",
    "    Unit_price = []\n",
    "    MRP_price = []\n",
    "    Prod_url = []\n",
    "    Asin = []\n",
    "\n",
    "    for card in cards:\n",
    "\n",
    "        # Extract title        \n",
    "        title = Extract_card(card,'.//div[@data-cy=\"title-recipe\"]')\n",
    "        if title.text.startswith('Sponsored'):\n",
    "            continue\n",
    "        if title:\n",
    "            Product_Title.append(title.text)\n",
    "        else:\n",
    "            Product_Title.append(0)\n",
    "\n",
    "\n",
    "        # Extract image link\n",
    "        image_link = Extract_card(card,'.//img[@class=\"s-image\"]')\n",
    "        if image_link:\n",
    "            image_src = image_link.get_attribute('src')\n",
    "            Image_url.append(image_src)\n",
    "        else:\n",
    "            Image_url.append(0)\n",
    "\n",
    "        # Extract rating        \n",
    "        rating = Extract_card(card,'.//div[@data-cy=\"reviews-block\"]//div[@class = \"a-row a-size-small\"]//span[@class=\"a-size-base s-underline-text\"]')\n",
    "        if rating:\n",
    "            No_of_ratings.append(rating.text.replace(\",\",\"\"))\n",
    "        else:\n",
    "            No_of_ratings.append(0)\n",
    "\n",
    "\n",
    "\n",
    "        # Extract Quantity        \n",
    "        qty = Extract_card(card,'.//div[@data-cy=\"reviews-block\"]//div[@class = \"a-row a-size-base\"][last()]')\n",
    "        if qty:\n",
    "            quantity = qty.text.split(\" \")[0].replace('+','')\n",
    "            if quantity[-1] == 'K':\n",
    "                actual_value = int(quantity[:-1])*1000\n",
    "            else:\n",
    "                actual_value = int(quantity[:-1])*10 + int(quantity[-1])\n",
    "            Quantity_sold.append(actual_value)\n",
    "        else:\n",
    "            Quantity_sold.append(0)\n",
    "\n",
    "\n",
    "        # Extract Selling Price        \n",
    "        sp = Extract_card(card,'.//div[@data-cy=\"price-recipe\"]//div[@class=\"a-row a-size-base a-color-base\"]//span[@class=\"a-price\"]//span[@class=\"a-price-whole\"]')\n",
    "        if sp:\n",
    "            Selling_price.append(sp.text.replace(\",\",\"\"))\n",
    "        else:\n",
    "            Selling_price.append(0)\n",
    "\n",
    "\n",
    "        # Extract Unit Price per 100ml        \n",
    "        up = Extract_card(card,'.//div[@data-cy=\"price-recipe\"]//div[@class=\"a-row a-size-base a-color-base\"]//span[@class=\"a-size-base a-color-secondary\"]//span[@class=\"a-price a-text-price\"]')\n",
    "        if up:\n",
    "            Unit_price.append(up.text[1:].replace(\",\",\"\"))\n",
    "        else:\n",
    "            Unit_price.append(0)\n",
    "\n",
    "\n",
    "\n",
    "        # Extract MRP Price        \n",
    "        mrp = Extract_card(card,'.//div[@data-cy=\"price-recipe\"]//div[@class=\"a-row a-size-base a-color-base\"]//div[@class=\"a-section aok-inline-block\"]//span[@class=\"a-price a-text-price\"]')\n",
    "        if mrp:\n",
    "            MRP_price.append(mrp.text[1:].replace(\",\",\"\"))\n",
    "        else:\n",
    "            MRP_price.append(0)\n",
    "\n",
    "        # Extract Product Link and ASIN Number        \n",
    "        prod_link = Extract_card(card,'.//div[@data-cy=\"title-recipe\"]//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "        if prod_link:\n",
    "            link = prod_link.get_attribute('href')\n",
    "            Prod_url.append(link.split('=')[0])\n",
    "\n",
    "            try:\n",
    "                url_parts = link.split(\"/\")\n",
    "                dp_index = url_parts.index(\"dp\")\n",
    "                asin = url_parts[dp_index + 1]\n",
    "                Asin.append(asin)\n",
    "\n",
    "            except:\n",
    "                Asin.append(0)\n",
    "\n",
    "        else:\n",
    "            Prod_url.append(0)\n",
    "\n",
    "    return Image_url,Product_Title,Quantity_sold,No_of_ratings,Selling_price,Unit_price,MRP_price,Prod_url,Asin\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b30dd64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_table(drive,path):\n",
    "    try:\n",
    "        content = drive.find_element('xpath',path)\n",
    "        return content.text.strip()\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def Brand_Scrape(df):\n",
    "    time_interval = 2\n",
    "\n",
    "    driver = webdriver.Firefox()\n",
    "    brands = []\n",
    "    urls = []\n",
    "    size = []\n",
    "    brand_value = []\n",
    "    scent = []\n",
    "    skin_type = []\n",
    "    benefits = []\n",
    "    item_form = []\n",
    "    item_weight = []\n",
    "    active_ingredient = []\n",
    "    unit_count = []\n",
    "    skin_tone = []\n",
    "    item_volume = []\n",
    "    special_feature = []\n",
    "    pack_size = []\n",
    "    spf_factor = []\n",
    "    hair_type = []\n",
    "    material_type_free = []\n",
    "    recomended_for = []\n",
    "    prefixes = [\"Visit the \", \"Brand: \"]\n",
    "    for index, row in df.iterrows():\n",
    "        amazon_url = row['Product_URL']\n",
    "        driver.get(amazon_url)\n",
    "\n",
    "        brand_name = Extract_table(driver,'//*[@id=\"bylineInfo\"]')\n",
    "        if brand_name:\n",
    "            if brand_name.startswith(\"Visit the \"):\n",
    "                brand_name = brand_name[len(\"Visit the \"):]\n",
    "            if brand_name.startswith(\"Brand: \"):\n",
    "                brand_name = brand_name[len(\"Brand: \"):]\n",
    "            if brand_name.endswith(\"Store\"):\n",
    "                brand_name = brand_name[:-5]\n",
    "        brands.append(brand_name)\n",
    "        urls.append(amazon_url)\n",
    "\n",
    "\n",
    "        ml = Extract_table(driver,'//*[@id=\"variation_size_name\"]//span[@class=\"selection\"]')\n",
    "        size.append(ml)\n",
    "             \n",
    "        bv = Extract_table(driver,'//tr[@class= \"a-spacing-small po-brand\"]//td[2]')\n",
    "        brand_value.append(bv)\n",
    "        \n",
    "        sc = Extract_table(driver,'//tr[@class= \"a-spacing-small po-scent\"]//td[2]')\n",
    "        scent.append(sc)\n",
    "        \n",
    "        sty = Extract_table(driver,'//tr[@class= \"a-spacing-small po-skin_type\"]//td[2]')\n",
    "        skin_type.append(sty)\n",
    "        \n",
    "        bf = Extract_table(driver,'//tr[@class= \"a-spacing-small po-product_benefit\"]//td[2]')\n",
    "        benefits.append(bf)\n",
    "        \n",
    "        itf = Extract_table(driver,'//tr[@class= \"a-spacing-small po-item_form\"]//td[2]')\n",
    "        item_form.append(itf)\n",
    "        \n",
    "        iw = Extract_table(driver,'//tr[@class= \"a-spacing-small po-item_weight\"]//td[2]')\n",
    "        item_weight.append(iw)\n",
    "        \n",
    "        ai = Extract_table(driver,'//tr[@class= \"a-spacing-small po-active_ingredients\"]//td[2]')\n",
    "        active_ingredient.append(ai)\n",
    "        \n",
    "        uc = Extract_table(driver,'//tr[@class= \"a-spacing-small po-unit_count\"]//td[2]')\n",
    "        unit_count.append(uc)\n",
    "        \n",
    "        st = Extract_table(driver,'//tr[@class= \"a-spacing-small po-skin_tone\"]//td[2]')\n",
    "        skin_tone.append(st)\n",
    "        \n",
    "        iv = Extract_table(driver,'//tr[@class= \"a-spacing-small po-item_volume\"]//td[2]')\n",
    "        item_volume.append(iv)\n",
    "        \n",
    "        ps = Extract_table(driver,'//tr[@class= \"a-spacing-small po-number_of_items\"]//td[2]')\n",
    "        pack_size.append(ps)\n",
    "        \n",
    "        spf = Extract_table(driver,'//tr[@class= \"a-spacing-small po-sun_protection_factor\"]//td[2]')\n",
    "        spf_factor.append(spf)\n",
    "        \n",
    "        ht = Extract_table(driver,'//tr[@class= \"a-spacing-small po-hair_type\"]//td[2]')\n",
    "        hair_type.append(ht)\n",
    "        \n",
    "        mt = Extract_table(driver,'//tr[@class= \"a-spacing-small po-material_type_free\"]//td[2]')\n",
    "        material_type_free.append(mt)\n",
    "        \n",
    "        sf = Extract_table(driver,'//tr[@class= \"a-spacing-small po-special_features\"]//td[2]')\n",
    "        special_feature.append(sf)\n",
    "        \n",
    "        rf = Extract_table(driver,'//tr[@class= \"a-spacing-small po-recommended_uses_for_product\"]//td[2]')\n",
    "        recomended_for.append(rf)        \n",
    "            \n",
    "        time.sleep(time_interval)\n",
    "    driver.close()\n",
    "\n",
    "    op_df = pd.DataFrame({\n",
    "'AZ_URL':urls,\n",
    "'Size_of_SKU':size,\n",
    "'Brand_Name':brands,\n",
    "'Brand_value':brand_value,\n",
    "'Scent_type':scent,\n",
    "'Skin_type':skin_type,\n",
    "'Benefits':benefits,\n",
    "'Item_form':item_form,\n",
    "'Item_weight':item_weight,\n",
    "'Active_ingredient':active_ingredient,\n",
    "'Unit_Count':unit_count,\n",
    "'Skin_tone':skin_tone,\n",
    "'Item_volume':item_volume,\n",
    "'Special_feature':special_feature,\n",
    "'Pack_size':pack_size,\n",
    "'SPF_factor':spf_factor,\n",
    "'Hair_type':hair_type,\n",
    "'Material_type_free':material_type_free,\n",
    "'Special_feature':special_feature,\n",
    "'Recomended_for':recomended_for,})\n",
    "    \n",
    "    return op_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "383e596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_competitor(df):\n",
    "    \n",
    "    df_grouped = df.groupby('Brand_Name')['Revenue'].sum().reset_index()\n",
    "    df_sorted = df_grouped.sort_values(by='Revenue', ascending=False)\n",
    "    top_10_brands = df_sorted.head(10)['Brand_Name'].tolist()\n",
    "    \n",
    "    return top_10_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d0a1f7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Card Scraping started at 2024-09-27 20:24:43.511114\n",
      "Hold your seat belt tight and enjoy the show !!!....\n",
      "Card Scraping done in : 0.3 mins\n",
      "Brand Scraping Started.... 2024-09-27 20:25:01.752834\n",
      "Brand name scraping done in : 4.7 mins\n",
      "Congrats!!! Market Sizing Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time_interval = 2\n",
    "\n",
    "# Define how many page to scrape\n",
    "num_of_pages = 1\n",
    "start_time = datetime.datetime.now()\n",
    "print('Card Scraping started at',start_time)\n",
    "print('Hold your seat belt tight and enjoy the show !!!....')\n",
    "\n",
    "categories = ['Face wash','Face Serum','Face Moisturizers','Shampoo','Conditioner','Hair Growth Serum',\n",
    "              'Sunscreen','Hair growth Oil','Body Lotion','Hair Mask','Facial Cleanser','Body Mist','EDP - Women','EDP - Men']\n",
    "\n",
    "keyword =\"Shampoo\"\n",
    "\n",
    "category_link = f'https://www.amazon.in/s?k={keyword.replace(\" \",\"+\")}&s=exact-aware-popularity-rank&page='\n",
    "\n",
    "Image_url_m = []\n",
    "Product_Title_m = []\n",
    "Quantity_sold_m = []\n",
    "No_of_ratings_m = [] \n",
    "Selling_price_m = []\n",
    "Unit_price_m = []\n",
    "MRP_price_m = []\n",
    "Prod_url_m = []\n",
    "Asin_m = []\n",
    "\n",
    "Top_brands = []\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "for i in range(1,num_of_pages+1):\n",
    "    url = category_link+str(i)\n",
    "    Image_url,Product_Title,Quantity_sold,No_of_ratings,Selling_price,Unit_price,MRP_price,Prod_url,Asin = Scrape_Page(driver,url)\n",
    "    Image_url_m.extend(Image_url)\n",
    "    Product_Title_m.extend(Product_Title)\n",
    "    Quantity_sold_m.extend(Quantity_sold)\n",
    "    No_of_ratings_m .extend(No_of_ratings)\n",
    "    Selling_price_m.extend(Selling_price)\n",
    "    Unit_price_m.extend(Unit_price)\n",
    "    MRP_price_m.extend(MRP_price)\n",
    "    Prod_url_m.extend(Prod_url)\n",
    "    Asin_m.extend(Asin)\n",
    "    time.sleep(time_interval)\n",
    "    \n",
    "driver.close()\n",
    "    \n",
    "df = pd.DataFrame({'Product_Title':Product_Title_m, 'ASIN':Asin_m,'Product_URL':Prod_url_m,'Image_URL':Image_url_m,\n",
    "                   'No_Of_Ratings':No_of_ratings_m,'MRP_Price':MRP_price_m,'Per_100ml_price':Unit_price_m,\n",
    "                   'Selling_Price':Selling_price_m,'Unit_Sold':Quantity_sold_m})\n",
    "# Drop the duplicates\n",
    "df_unique = df.drop_duplicates(subset='ASIN')\n",
    "\n",
    "# Calculate the max unit slold\n",
    "df_unique['Max_Unit_Sold'] = df_unique['Unit_Sold'].apply(calculate_maxunitsold)\n",
    "\n",
    "df_unique[['No_Of_Ratings', 'MRP_Price','Selling_Price']] = df_unique[['No_Of_Ratings', 'MRP_Price','Selling_Price']].astype(int)\n",
    "df_unique[['Per_100ml_price']] = df_unique[['Per_100ml_price']].astype(float)\n",
    " \n",
    "\n",
    "# Calculate the revenue\n",
    "df_unique['Revenue'] = df_unique['Unit_Sold'] * df_unique['Selling_Price']\n",
    "df_unique['Max_Revenue'] = df_unique['Max_Unit_Sold'] * df_unique['Selling_Price']\n",
    "\n",
    "\n",
    "# Calculate the contribution of each product\n",
    "total_revenue = df_unique['Revenue'].sum()\n",
    "df_unique['Contribution'] = (df_unique['Revenue'] / total_revenue)\n",
    "\n",
    "\n",
    "# Sort the DataFrame by contribution in descending order\n",
    "df_unique = df_unique.sort_values('Contribution', ascending=False)\n",
    "df_unique['Rolling_sum'] = df_unique['Contribution'].cumsum()\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "card_time_taken = round((end_time - start_time).total_seconds() / 60,1)\n",
    "print(f'Card Scraping done in : {card_time_taken} mins')\n",
    "# df_unique.to_csv(f'{keyword}_MS_without_brand.csv',index=False)\n",
    "\n",
    "\n",
    "print('Brand Scraping Started....',end_time)\n",
    "brand_df = Brand_Scrape(df_unique)\n",
    "\n",
    "final_op = pd.merge(df_unique, brand_df, how='left', left_on='Product_URL', right_on='AZ_URL')\n",
    "\n",
    "final_op.drop(columns=['AZ_URL'], inplace=True)\n",
    "final_op['Category'] = keyword\n",
    "\n",
    "# exporting the competitor\n",
    "Top_brands = Find_competitor(final_op)\n",
    "Competitor = final_op[final_op['Brand_Name'].isin(Top_brands)]\n",
    "Competitor.to_csv(f'{keyword}_Competitor_of_Pilgrim.csv',index=False)\n",
    "\n",
    "# Exporting Pilgrim's product\n",
    "Pilgrim = final_op[final_op['Brand_Name'] == 'Pilgrim']\n",
    "Pilgrim.to_csv(f'{keyword}_Products_of_Pilgrim.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "brand_time_taken = round((datetime.datetime.now() - end_time).total_seconds() / 60,1)\n",
    "print(f'Brand name scraping done in : {brand_time_taken} mins')\n",
    "\n",
    "final_op.to_csv(f'{keyword}_MS_with_brand.csv',index=False)\n",
    "print(\"Congrats!!! Market Sizing Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa1e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
